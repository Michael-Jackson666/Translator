#!/usr/bin/env python3
"""
æ‰¹é‡ç¿»è¯‘è„šæœ¬
ä½¿ç”¨è®­ç»ƒå¥½çš„Transformeræ¨¡å‹è¿›è¡Œæ‰¹é‡è‹±è¯­åˆ°æ³•è¯­ç¿»è¯‘
"""

import torch
from torch import nn
import math
import os
import collections

# === è¯æ±‡è¡¨ç±» ===
class Vocab:
    """è¯è¡¨"""
    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):
        if tokens is None:
            tokens = []
        if reserved_tokens is None:
            reserved_tokens = []
        # ç»Ÿè®¡è¯é¢‘
        counter = collections.Counter()
        for token_list in tokens:
            counter.update(token_list)
        
        self._token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)
        
        # æ„å»ºè¯æ±‡è¡¨ï¼šä¿ç•™è¯å…ƒ + é«˜é¢‘è¯å…ƒ
        self.idx_to_token = list(reserved_tokens)
        self.token_to_idx = {token: idx for idx, token in enumerate(self.idx_to_token)}
        
        for token, freq in self._token_freqs:
            if freq < min_freq:
                break
            if token not in self.token_to_idx:
                self.idx_to_token.append(token)
                self.token_to_idx[token] = len(self.idx_to_token) - 1
    
    def __len__(self):
        return len(self.idx_to_token)
    
    def __getitem__(self, tokens):
        if not isinstance(tokens, (list, tuple)):
            return self.token_to_idx.get(tokens, self.unk)
        return [self.__getitem__(token) for token in tokens]
    
    def to_tokens(self, indices):
        if not isinstance(indices, (list, tuple)):
            return self.idx_to_token[indices]
        return [self.idx_to_token[index] for index in indices]
    
    @property
    def unk(self):  # æœªçŸ¥è¯å…ƒçš„ç´¢å¼•ä¸º0
        return 0
    
    @property 
    def token_freqs(self):
        return self._token_freqs

# === å·¥å…·å‡½æ•° ===
def sequence_mask(X, valid_len, value=0):
    """åœ¨åºåˆ—ä¸­å±è”½ä¸ç›¸å…³çš„é¡¹"""
    maxlen = X.size(1)
    mask = torch.arange((maxlen), dtype=torch.float32,
                        device=X.device)[None, :] < valid_len[:, None]
    X[~mask] = value
    return X

def masked_softmax(X, valid_lens):
    """é€šè¿‡åœ¨æœ€åä¸€ä¸ªè½´ä¸Šæ©è”½å…ƒç´ æ¥æ‰§è¡Œsoftmaxæ“ä½œ"""
    if valid_lens is None:
        return nn.functional.softmax(X, dim=-1)
    else:
        shape = X.shape
        if valid_lens.dim() == 1:
            valid_lens = torch.repeat_interleave(valid_lens, shape[1])
        else:
            valid_lens = valid_lens.reshape(-1)
        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)
        return nn.functional.softmax(X.reshape(shape), dim=-1)

# === æ³¨æ„åŠ›æœºåˆ¶ ===
class DotProductAttention(nn.Module):
    """ç¼©æ”¾ç‚¹ç§¯æ³¨æ„åŠ›"""
    def __init__(self, dropout, **kwargs):
        super(DotProductAttention, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)

    def forward(self, queries, keys, values, valid_lens=None):
        d = queries.shape[-1]
        scores = torch.bmm(queries, keys.transpose(1,2)) / math.sqrt(d)
        self.attention_weights = masked_softmax(scores, valid_lens)
        return torch.bmm(self.dropout(self.attention_weights), values)

def transpose_qkv(X, num_heads):
    """ä¸ºäº†å¤šæ³¨æ„åŠ›å¤´çš„å¹¶è¡Œè®¡ç®—è€Œå˜æ¢å½¢çŠ¶"""
    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)
    X = X.permute(0, 2, 1, 3)
    return X.reshape(-1, X.shape[2], X.shape[3])

def transpose_output(X, num_heads):
    """é€†è½¬transpose_qkvå‡½æ•°çš„æ“ä½œ"""
    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])
    X = X.permute(0, 2, 1, 3)
    return X.reshape(X.shape[0], X.shape[1], -1)

class MultiHeadAttention(nn.Module):
    """å¤šå¤´æ³¨æ„åŠ›"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 num_heads, dropout, bias=False, **kwargs):
        super(MultiHeadAttention, self).__init__(**kwargs)
        self.num_heads = num_heads
        self.attention = DotProductAttention(dropout)
        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)
        self.W_k = nn.Linear(key_size, num_hiddens, bias=bias)
        self.W_v = nn.Linear(value_size, num_hiddens, bias=bias)
        self.W_o = nn.Linear(num_hiddens, num_hiddens, bias=bias)

    def forward(self, queries, keys, values, valid_lens):
        queries = self.W_q(queries)
        keys = self.W_k(keys)
        values = self.W_v(values)

        queries = transpose_qkv(queries, self.num_heads)
        keys = transpose_qkv(keys, self.num_heads)
        values = transpose_qkv(values, self.num_heads)

        if valid_lens is not None:
            valid_lens = torch.repeat_interleave(
                valid_lens, repeats=self.num_heads, dim=0)

        output = self.attention(queries, keys, values, valid_lens)
        output_concat = transpose_output(output, self.num_heads)
        return self.W_o(output_concat)

# === ä½ç½®ç¼–ç  ===
class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    def __init__(self, num_hiddens, dropout, max_len=1000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(dropout)
        self.P = torch.zeros((1, max_len, num_hiddens))
        X = torch.arange(max_len, dtype=torch.float32).reshape(
            -1, 1) / torch.pow(10000, torch.arange(
            0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)
        self.P[:, :, 0::2] = torch.sin(X)
        self.P[:, :, 1::2] = torch.cos(X)

    def forward(self, X):
        X = X + self.P[:, :X.shape[1], :].to(X.device)
        return self.dropout(X)

# === Transformerç»„ä»¶ ===
class PositionWiseFFN(nn.Module):
    """åŸºäºä½ç½®çš„å‰é¦ˆç½‘ç»œ"""
    def __init__(self, ffn_num_input, ffn_num_hiddens, ffn_num_outputs, **kwargs):
        super(PositionWiseFFN, self).__init__(**kwargs)
        self.dense1 = nn.Linear(ffn_num_input, ffn_num_hiddens)
        self.relu = nn.ReLU()
        self.dense2 = nn.Linear(ffn_num_hiddens, ffn_num_outputs)

    def forward(self, X):
        return self.dense2(self.relu(self.dense1(X)))

class AddNorm(nn.Module):
    """æ®‹å·®è¿æ¥åè¿›è¡Œå±‚è§„èŒƒåŒ–"""
    def __init__(self, normalized_shape, dropout, **kwargs):
        super(AddNorm, self).__init__(**kwargs)
        self.dropout = nn.Dropout(dropout)
        self.ln = nn.LayerNorm(normalized_shape)

    def forward(self, X, Y):
        return self.ln(self.dropout(Y) + X)

class TransformerEncoderBlock(nn.Module):
    """Transformerç¼–ç å™¨å—"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                 dropout, use_bias=False, **kwargs):
        super(TransformerEncoderBlock, self).__init__(**kwargs)
        self.attention = MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout, use_bias)
        self.addnorm1 = AddNorm(norm_shape, dropout)
        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)
        self.addnorm2 = AddNorm(norm_shape, dropout)

    def forward(self, X, valid_lens):
        Y = self.addnorm1(X, self.attention(X, X, X, valid_lens))
        return self.addnorm2(Y, self.ffn(Y))

class TransformerEncoder(nn.Module):
    """Transformerç¼–ç å™¨"""
    def __init__(self, vocab_size, key_size, query_size, value_size,
                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,
                 num_heads, num_layers, dropout, use_bias=False, **kwargs):
        super(TransformerEncoder, self).__init__(**kwargs)
        self.num_hiddens = num_hiddens
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module("block_"+str(i),
                TransformerEncoderBlock(key_size, query_size, value_size, num_hiddens,
                             norm_shape, ffn_num_input, ffn_num_hiddens,
                             num_heads, dropout, use_bias))

    def forward(self, X, valid_lens, *args):
        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self.attention_weights = [None] * len(self.blks)
        for i, blk in enumerate(self.blks):
            X = blk(X, valid_lens)
            self.attention_weights[i] = blk.attention.attention.attention_weights
        return X

class TransformerDecoderBlock(nn.Module):
    """è§£ç å™¨ä¸­ç¬¬iä¸ªå—"""
    def __init__(self, key_size, query_size, value_size, num_hiddens,
                 norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                 dropout, i, **kwargs):
        super(TransformerDecoderBlock, self).__init__(**kwargs)
        self.i = i
        self.attention1 = MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm1 = AddNorm(norm_shape, dropout)
        self.attention2 = MultiHeadAttention(
            key_size, query_size, value_size, num_hiddens, num_heads, dropout)
        self.addnorm2 = AddNorm(norm_shape, dropout)
        self.ffn = PositionWiseFFN(ffn_num_input, ffn_num_hiddens, num_hiddens)
        self.addnorm3 = AddNorm(norm_shape, dropout)

    def forward(self, X, state):
        enc_outputs, enc_valid_lens = state[0], state[1]
        if state[2][self.i] is None:
            key_values = X
        else:
            key_values = torch.cat((state[2][self.i], X), axis=1)
        state[2][self.i] = key_values
        if self.training:
            batch_size, num_steps, _ = X.shape
            dec_valid_lens = torch.arange(
                1, num_steps + 1, device=X.device).repeat(batch_size, 1)
        else:
            dec_valid_lens = None

        X2 = self.attention1(X, key_values, key_values, dec_valid_lens)
        Y = self.addnorm1(X, X2)
        Y2 = self.attention2(Y, enc_outputs, enc_outputs, enc_valid_lens)
        Z = self.addnorm2(Y, Y2)
        return self.addnorm3(Z, self.ffn(Z)), state

class TransformerDecoder(nn.Module):
    def __init__(self, vocab_size, key_size, query_size, value_size,
                 num_hiddens, norm_shape, ffn_num_input, ffn_num_hiddens,
                 num_heads, num_layers, dropout, **kwargs):
        super(TransformerDecoder, self).__init__(**kwargs)
        self.num_hiddens = num_hiddens
        self.num_layers = num_layers
        self.embedding = nn.Embedding(vocab_size, num_hiddens)
        self.pos_encoding = PositionalEncoding(num_hiddens, dropout)
        self.blks = nn.Sequential()
        for i in range(num_layers):
            self.blks.add_module("block_"+str(i),
                TransformerDecoderBlock(key_size, query_size, value_size, num_hiddens,
                             norm_shape, ffn_num_input, ffn_num_hiddens,
                             num_heads, dropout, i))
        self.dense = nn.Linear(num_hiddens, vocab_size)

    def init_state(self, enc_outputs, enc_valid_lens, *args):
        return [enc_outputs, enc_valid_lens, [None] * self.num_layers]

    def forward(self, X, state):
        X = self.pos_encoding(self.embedding(X) * math.sqrt(self.num_hiddens))
        self._attention_weights = [[None] * len(self.blks) for _ in range (2)]
        for i, blk in enumerate(self.blks):
            X, state = blk(X, state)
            self._attention_weights[0][i] = blk.attention1.attention.attention_weights
            self._attention_weights[1][i] = blk.attention2.attention.attention_weights
        return self.dense(X), state

    @property
    def attention_weights(self):
        return self._attention_weights

class EncoderDecoder(nn.Module):
    """ç¼–ç å™¨-è§£ç å™¨æ¶æ„çš„åŸºç±»"""
    def __init__(self, encoder, decoder, **kwargs):
        super(EncoderDecoder, self).__init__(**kwargs)
        self.encoder = encoder
        self.decoder = decoder

    def forward(self, enc_X, dec_X, *args):
        enc_outputs = self.encoder(enc_X, *args)
        dec_state = self.decoder.init_state(enc_outputs, *args)
        return self.decoder(dec_X, dec_state)

# === æ‰¹é‡ç¿»è¯‘å™¨ç±» ===
class BatchTranslator:
    """æ‰¹é‡ç¿»è¯‘å™¨"""
    
    def __init__(self, model_path):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_path = model_path
        self.net, self.src_vocab, self.tgt_vocab = self._load_model()
    
    def _truncate_pad(self, line, num_steps, padding_token):
        if len(line) > num_steps:
            return line[:num_steps]
        return line + [padding_token] * (num_steps - len(line))
    
    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")
        
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
        # åŠ è½½æ¨¡å‹æ–‡ä»¶ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬çš„PyTorch
        try:
            checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=False)
        except TypeError:
            checkpoint = torch.load(self.model_path, map_location=self.device)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´çš„checkpointæ ¼å¼
        if 'model_state_dict' in checkpoint:
            src_vocab = checkpoint['src_vocab']
            tgt_vocab = checkpoint['tgt_vocab']
            
            # ä½¿ç”¨è®­ç»ƒæ—¶çš„å‚æ•°é‡å»ºæ¨¡å‹
            num_hiddens, num_layers, dropout = 32, 2, 0.1
            ffn_num_input, ffn_num_hiddens, num_heads = 32, 64, 4
            key_size, query_size, value_size = 32, 32, 32
            norm_shape = [32]
            
            encoder = TransformerEncoder(
                len(src_vocab), key_size, query_size, value_size, num_hiddens,
                norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                num_layers, dropout)
            decoder = TransformerDecoder(
                len(tgt_vocab), key_size, query_size, value_size, num_hiddens,
                norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,
                num_layers, dropout)
            net = EncoderDecoder(encoder, decoder)
            net.load_state_dict(checkpoint['model_state_dict'])
        else:
            raise ValueError("ä¸æ”¯æŒçš„æ¨¡å‹æ ¼å¼")
        
        net.to(self.device)
        net.eval()
        print(f"æ¨¡å‹å·²åŠ è½½åˆ° {self.device}")
        return net, src_vocab, tgt_vocab
    
    def translate_single(self, sentence):
        """ç¿»è¯‘å•ä¸ªå¥å­"""
        # ç¡®ä¿å¥å­ä»¥æ ‡ç‚¹ç¬¦å·ç»“å°¾
        if not sentence.strip().endswith(('.', '!', '?')):
            sentence = sentence.strip() + ' .'
        
        # é¢„å¤„ç†: è½¬æ¢ä¸ºå°å†™å¹¶åˆ†è¯
        src_tokens = self.src_vocab[sentence.lower().split(' ')] + [self.src_vocab['<eos>']]
        enc_valid_len = torch.tensor([len(src_tokens)], device=self.device)
        
        # æˆªæ–­æˆ–å¡«å……åˆ°å›ºå®šé•¿åº¦
        num_steps = 15
        src_tokens = self._truncate_pad(src_tokens, num_steps, self.src_vocab['<pad>'])
        enc_X = torch.unsqueeze(
            torch.tensor(src_tokens, dtype=torch.long, device=self.device), dim=0)
        
        # ç¼–ç 
        enc_outputs = self.net.encoder(enc_X, enc_valid_len)
        dec_state = self.net.decoder.init_state(enc_outputs, enc_valid_len)
        
        # è§£ç 
        dec_X = torch.unsqueeze(torch.tensor(
            [self.tgt_vocab['<bos>']], dtype=torch.long, device=self.device), dim=0)
        output_seq = []
        
        for _ in range(num_steps):
            Y, dec_state = self.net.decoder(dec_X, dec_state)
            dec_X = Y.argmax(dim=2)
            pred = dec_X.squeeze(dim=0).type(torch.int32).item()
            if pred == self.tgt_vocab['<eos>']:
                break
            output_seq.append(pred)
        
        return ' '.join(self.tgt_vocab.to_tokens(output_seq))
    
    def translate_batch(self, sentences, show_progress=True):
        """æ‰¹é‡ç¿»è¯‘å¤šä¸ªå¥å­"""
        results = []
        total = len(sentences)
        
        print(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {total} ä¸ªå¥å­...")
        
        for i, sentence in enumerate(sentences):
            try:
                if show_progress:
                    print(f"è¿›åº¦: {i+1}/{total} - æ­£åœ¨ç¿»è¯‘: {sentence[:30]}{'...' if len(sentence) > 30 else ''}")
                
                translation = self.translate_single(sentence)
                results.append(translation)
                
            except Exception as e:
                print(f"ç¿»è¯‘å¥å­ '{sentence}' æ—¶å‡ºé”™: {e}")
                results.append(f"[ç¿»è¯‘å¤±è´¥: {str(e)}]")
        
        print(f"æ‰¹é‡ç¿»è¯‘å®Œæˆï¼æˆåŠŸç¿»è¯‘ {len([r for r in results if not r.startswith('[ç¿»è¯‘å¤±è´¥')])} ä¸ªå¥å­")
        return results

# === ä¾¿åˆ©å‡½æ•° ===
def translate_sentences(model_path, sentences):
    """
    æ‰¹é‡ç¿»è¯‘å¥å­çš„ä¾¿åˆ©å‡½æ•°
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        sentences: è¦ç¿»è¯‘çš„è‹±è¯­å¥å­åˆ—è¡¨
    
    Returns:
        ç¿»è¯‘åçš„æ³•è¯­å¥å­åˆ—è¡¨
    """
    translator = BatchTranslator(model_path)
    return translator.translate_batch(sentences)

def translate_from_file(model_path, input_file, output_file=None):
    """
    ä»æ–‡ä»¶è¯»å–å¥å­è¿›è¡Œæ‰¹é‡ç¿»è¯‘
    
    Args:
        model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ¯è¡Œä¸€ä¸ªè‹±è¯­å¥å­ï¼‰
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºè¾“å…¥æ–‡ä»¶å_translated.txtï¼‰
    """
    # è¯»å–è¾“å…¥æ–‡ä»¶
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            sentences = [line.strip() for line in f if line.strip()]
    except FileNotFoundError:
        print(f"é”™è¯¯: è¾“å…¥æ–‡ä»¶ {input_file} ä¸å­˜åœ¨ï¼")
        return
    
    # è®¾ç½®è¾“å‡ºæ–‡ä»¶å
    if output_file is None:
        base_name = os.path.splitext(input_file)[0]
        output_file = f"{base_name}_translated.txt"
    
    # æ‰¹é‡ç¿»è¯‘
    translator = BatchTranslator(model_path)
    translations = translator.translate_batch(sentences)
    
    # ä¿å­˜ç»“æœ
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            for eng, fra in zip(sentences, translations):
                f.write(f"EN: {eng}\n")
                f.write(f"FR: {fra}\n")
                f.write("-" * 50 + "\n")
        
        print(f"ç¿»è¯‘ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°ï¼šæ¼”ç¤ºæ‰¹é‡ç¿»è¯‘åŠŸèƒ½"""
    model_path = 'transformer_fra_eng.pth'
    
    if not os.path.exists(model_path):
        print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨ï¼")
        print("è¯·å…ˆè¿è¡Œ transformer-d2l.py è¿›è¡Œè®­ç»ƒã€‚")
        return
    
    # ç¤ºä¾‹è‹±è¯­å¥å­
    test_sentences = [
        'hello .',
        'how are you ?',
        'i am fine .',
        'good morning .',
        'see you later .',
        'i love you .',
        'thank you .',
        'what is your name ?',
        'i am learning french .',
        'this is a beautiful day .',
        'where are you from ?',
        'i like to read books .',
        'the weather is nice today .',
        'can you help me ?',
        'i want to go home .'
    ]
    
    print("=" * 60)
    print("ğŸŒ æ‰¹é‡ç¿»è¯‘ç¤ºä¾‹")
    print("ä½¿ç”¨è®­ç»ƒå¥½çš„Transformeræ¨¡å‹è¿›è¡Œè‹±è¯­åˆ°æ³•è¯­ç¿»è¯‘")
    print("=" * 60)
    
    try:
        # åˆ›å»ºæ‰¹é‡ç¿»è¯‘å™¨
        translator = BatchTranslator(model_path)
        
        # è¿›è¡Œæ‰¹é‡ç¿»è¯‘
        print(f"\nå¼€å§‹ç¿»è¯‘ {len(test_sentences)} ä¸ªå¥å­...")
        results = translator.translate_batch(test_sentences, show_progress=True)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\n{'='*60}")
        print("ğŸ“‹ ç¿»è¯‘ç»“æœå¯¹æ¯”:")
        print(f"{'='*60}")
        
        for i, (eng, fra) in enumerate(zip(test_sentences, results), 1):
            print(f"{i:2d}. è‹±è¯­: {eng}")
            print(f"    æ³•è¯­: {fra}")
            print("-" * 50)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_file = "batch_translation_results.txt"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("æ‰¹é‡ç¿»è¯‘ç»“æœ\n")
            f.write("=" * 50 + "\n\n")
            for i, (eng, fra) in enumerate(zip(test_sentences, results), 1):
                f.write(f"{i:2d}. è‹±è¯­: {eng}\n")
                f.write(f"    æ³•è¯­: {fra}\n")
                f.write("-" * 30 + "\n")
        
        print(f"âœ… ç¿»è¯‘ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # æ¼”ç¤ºä»æ–‡ä»¶ç¿»è¯‘çš„åŠŸèƒ½
        print(f"\n{'='*60}")
        print("ğŸ“„ æ–‡ä»¶ç¿»è¯‘æ¼”ç¤º:")
        print(f"{'='*60}")
        
        # åˆ›å»ºç¤ºä¾‹è¾“å…¥æ–‡ä»¶
        input_file = "example_input.txt"
        with open(input_file, 'w', encoding='utf-8') as f:
            f.write("hello world .\n")
            f.write("i am happy .\n")
            f.write("good luck .\n")
            f.write("have a nice day .\n")
        
        print(f"åˆ›å»ºç¤ºä¾‹è¾“å…¥æ–‡ä»¶: {input_file}")
        translate_from_file(model_path, input_file)
        
    except Exception as e:
        print(f"âŒ æ‰¹é‡ç¿»è¯‘æ—¶å‡ºé”™: {e}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶æ­£ç¡®ä¸”å®Œæ•´")

# === å‘½ä»¤è¡Œæ¥å£ ===
if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1:
        # å‘½ä»¤è¡Œæ¨¡å¼
        if sys.argv[1] == "--file" and len(sys.argv) >= 3:
            # ä»æ–‡ä»¶ç¿»è¯‘
            input_file = sys.argv[2]
            output_file = sys.argv[3] if len(sys.argv) > 3 else None
            model_path = sys.argv[4] if len(sys.argv) > 4 else 'transformer_fra_eng.pth'
            
            print(f"ä»æ–‡ä»¶ {input_file} è¿›è¡Œæ‰¹é‡ç¿»è¯‘...")
            translate_from_file(model_path, input_file, output_file)
            
        elif sys.argv[1] == "--sentences":
            # ä»å‘½ä»¤è¡Œå‚æ•°ç¿»è¯‘
            sentences = sys.argv[2:]
            model_path = 'transformer_fra_eng.pth'
            
            if not sentences:
                print("é”™è¯¯: è¯·æä¾›è¦ç¿»è¯‘çš„å¥å­")
                print("ç”¨æ³•: python batch_translate.py --sentences \"å¥å­1\" \"å¥å­2\" ...")
                sys.exit(1)
            
            print(f"ç¿»è¯‘ {len(sentences)} ä¸ªå¥å­...")
            results = translate_sentences(model_path, sentences)
            
            for eng, fra in zip(sentences, results):
                print(f"è‹±è¯­: {eng}")
                print(f"æ³•è¯­: {fra}")
                print("-" * 30)
                
        else:
            print("ç”¨æ³•:")
            print("  æ¼”ç¤ºæ¨¡å¼: python batch_translate.py")
            print("  æ–‡ä»¶æ¨¡å¼: python batch_translate.py --file input.txt [output.txt] [model.pth]")
            print("  å¥å­æ¨¡å¼: python batch_translate.py --sentences \"å¥å­1\" \"å¥å­2\" ...")
    else:
        # æ¼”ç¤ºæ¨¡å¼
        main()
